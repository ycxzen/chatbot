language: "zh"




#pipeline:
#- name: HFTransformersNLP
#  model_name: "bert"
#  model_weights: "bert-base-chinese"
#  cache_dir: ./HFTr
#- name: "LanguageModelTokenizer"
##  "intent_tokenization_flag": True
##  "intent_split_symbol": "-"
#- name: "LanguageModelFeaturizer"
##- name: "JiebaTokenizer"
##  dictionary_path: "./user_dict.txt"
##- name: "CRFEntityExtractor"
#- name: "DIETClassifier"
##  "entity_recognition": False

#policies:
#  - name: MemoizationPolicy
#    max_history: 1
#  - name: AugmentedMemoizationPolicy
#    max_history: 3
#  - name: FormPolicy
#  - name: FallbackPolicy
policies:
# # No configuration for policies was provided. The following default policies were used to train your model.
# # If you'd like to customize them, uncomment and adjust the policies.
# # See https://rasa.com/docs/rasa/policies for more information.
   - name: MemoizationPolicy
   - name: TEDPolicy
     max_history: 5
     epochs: 100
     constrain_similarities: true
     model_confidence: cosine
   - name: RulePolicy
pipeline:
# # No configuration for the NLU pipeline was provided. The following default pipeline was used to train your model.
# # If you'd like to customize it, uncomment and adjust the pipeline.
# # See https://rasa.com/docs/rasa/tuning-your-model for more information.
- name: "JiebaTokenizer"
  # Flag to check whether to split intents
  "intent_tokenization_flag": False
  # Symbol on which intent should be split
  "intent_split_symbol": "_"
  # Regular expression to detect tokens
  "token_pattern": None
- name: RegexFeaturizer
- name: LexicalSyntacticFeaturizer
- name: CountVectorsFeaturizer
- name: CountVectorsFeaturizer
- name: DIETClassifier
- name: EntitySynonymMapper
- name: ResponseSelector
- name: FallbackClassifier
